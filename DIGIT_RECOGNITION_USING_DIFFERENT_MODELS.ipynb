{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3H_i5zRvVOq",
        "outputId": "fd5509e5-9990-4d2d-9fac-f2332baf5bf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "data = load_dataset(\"ylecun/mnist\")\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_oRJxXsvsKQ",
        "outputId": "eaf9b78f-22e1-4035-fe82-81d6a98addf8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['image', 'label'],\n",
              "        num_rows: 60000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['image', 'label'],\n",
              "        num_rows: 10000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing of the data\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "train_images = np.array(data[\"train\"][\"image\"])\n",
        "train_labels = np.array(data[\"train\"][\"label\"])\n",
        "\n",
        "test_images = np.array(data[\"test\"][\"image\"])\n",
        "test_labels = np.array(data[\"test\"][\"label\"])\n",
        "\n",
        "# Normalization of all teh data\n",
        "train_images_norm=train_images/255\n",
        "test_images_norm=test_images/255\n",
        "\n",
        "n1=train_images.shape[0]\n",
        "n2=test_images.shape[0]\n",
        "\n",
        "# Flattening the data to make it 1-D from 2-D\n",
        "train_images_flat=train_images_norm.reshape([n1,-1])\n",
        "test_images_flat=test_images_norm.reshape([n2,-1])"
      ],
      "metadata": {
        "id": "GnaTxT5TvxVr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset to be taken\n",
        "x_train=train_images_flat[0:10000]\n",
        "y_train=train_labels[0:10000]\n",
        "x_test=train_images_flat[0:2000]\n",
        "y_test=test_labels[0:2000]"
      ],
      "metadata": {
        "id": "gd0ssk8EwV6V"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vanilla Linear Regression"
      ],
      "metadata": {
        "id": "lC005Oh21WLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "# Training using vanilla Linear Regression Model\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(x_train, y_train)\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculating training time\n",
        "training_time_model_1 = end_time-start_time\n",
        "\n",
        "# Predicting the value on test and rounding it off to closest integer and cliping it from 0 to 9\n",
        "y_pred = lin_reg.predict(x_test)\n",
        "y_pred = np.round(y_pred).astype(int)\n",
        "y_pred = np.clip(y_pred, 0, 9)"
      ],
      "metadata": {
        "id": "9LGx4-XC0xtK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding accuracy, precision, recall and f1 score for the model\n",
        "accuracy_percentage_model_1=(accuracy_score(y_test,y_pred))*100\n",
        "precision_percentage_model_1=(precision_score(y_test, y_pred, average=\"weighted\"))*100\n",
        "recall_percentage_model_1=(recall_score(y_test,y_pred, average=\"weighted\"))*100\n",
        "f1_percentage_model_1=(f1_score(y_test,y_pred, average=\"weighted\"))*100\n",
        "\n",
        "print(\"Vanilla Linear Regression Stats:\")\n",
        "print(f\"Accuracy: {accuracy_percentage_model_1:.2f}%\")\n",
        "print(f\"Precision: {precision_percentage_model_1:.2f}%\")\n",
        "print(f\"Recall: {recall_percentage_model_1:.2f}%\")\n",
        "print(f\"F1 Score: {f1_percentage_model_1:.2f}%\")\n",
        "print(f\"Training time: {training_time_model_1:.2f}sec\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yv0CivhNBzza",
        "outputId": "9cb16780-2f6d-4e39-8ef1-17466e284907"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vanilla Linear Regression Stats:\n",
            "Accuracy: 9.45%\n",
            "Precision: 9.49%\n",
            "Recall: 9.45%\n",
            "F1 Score: 9.04%\n",
            "Training time: 1.12sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Polynomial Regression\n",
        "This can't be performed as each digit has 28 * 28 parameters which make 28 * 28 * 28 * 28 coefficients for degree 2 amking it intensively high for the computer to handle. \\\n",
        "So, we can reduce the dimension of it to 2 or 3 using PCA or tSNE and then apply polynomial regression."
      ],
      "metadata": {
        "id": "RR5Eyy2DHnV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Apply PCA to reduce to 2 dimensions\n",
        "pca = PCA(n_components=2)\n",
        "x_train_pca = pca.fit_transform(x_train)\n",
        "x_test_pca = pca.transform(x_test)\n",
        "\n",
        "start_time = time.time()\n",
        "degree = 5\n",
        "poly = PolynomialFeatures(degree=degree)\n",
        "x_train_poly = poly.fit_transform(x_train_pca)\n",
        "x_test_poly = poly.fit_transform(x_test_pca)\n",
        "\n",
        "lin_reg_2 = LinearRegression()\n",
        "lin_reg_2.fit(x_train_poly,y_train)\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculating training time\n",
        "training_time_model_2 = end_time-start_time\n",
        "\n",
        "# Predicting the value on test and rounding it off to closest integer and cliping it from 0 to 9\n",
        "y_pred = lin_reg_2.predict(x_test_poly)\n",
        "y_pred = np.round(y_pred).astype(int)\n",
        "y_pred = np.clip(y_pred, 0, 9)"
      ],
      "metadata": {
        "id": "e3b0Sl1NM4Ya"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding accuracy, precision, recall and f1 score for the model\n",
        "accuracy_percentage_model_2=(accuracy_score(y_test,y_pred))*100\n",
        "precision_percentage_model_2=(precision_score(y_test, y_pred, average=\"weighted\"))*100\n",
        "recall_percentage_model_2=(recall_score(y_test,y_pred, average=\"weighted\"))*100\n",
        "f1_percentage_model_2=(f1_score(y_test,y_pred, average=\"weighted\"))*100\n",
        "\n",
        "print(\"Vanilla Linear Regression Stats:\")\n",
        "print(f\"Accuracy: {accuracy_percentage_model_2:.2f}%\")\n",
        "print(f\"Precision: {precision_percentage_model_2:.2f}%\")\n",
        "print(f\"Recall: {recall_percentage_model_2:.2f}%\")\n",
        "print(f\"F1 Score: {f1_percentage_model_2:.2f}%\")\n",
        "print(f\"Training time: {training_time_model_2:.2f}sec\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edpztHz0On7D",
        "outputId": "cf5a623b-68ab-4e2a-bea2-1e3eeda4b002"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vanilla Linear Regression Stats:\n",
            "Accuracy: 10.25%\n",
            "Precision: 9.33%\n",
            "Recall: 10.25%\n",
            "F1 Score: 8.74%\n",
            "Training time: 0.06sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Guassian Basis Function Regression"
      ],
      "metadata": {
        "id": "v_3mGcaOPPyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Apply PCA to reduce to 1 dimensions\n",
        "pca = PCA(n_components=1)\n",
        "x_train_pca = pca.fit_transform(x_train)\n",
        "x_test_pca = pca.transform(x_test)\n",
        "\n",
        "# Creating Gaussian basis functions\n",
        "start_time = time.time()\n",
        "degree = 50\n",
        "centers = np.linspace(-10, 10, degree).reshape(-1, 1)\n",
        "sigma = 2.0  # Standard deviation of Gaussians\n",
        "\n",
        "# Compute Gaussian basis functions\n",
        "x_train_g = np.exp(-((x_train_pca - centers.T) ** 2) / (2 * sigma**2))\n",
        "x_test_g = np.exp(-((x_test_pca - centers.T) ** 2) / (2 * sigma**2))\n",
        "\n",
        "# Train Linear Regression model\n",
        "lin_reg_3 = LinearRegression()\n",
        "lin_reg_3.fit(x_train_g, y_train)\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculating training time\n",
        "training_time_model_3 = end_time-start_time\n",
        "\n",
        "# Make predictions\n",
        "y_pred = lin_reg_3.predict(x_test_g)\n",
        "y_pred = np.round(y_pred).astype(int)\n",
        "y_pred = np.clip(y_pred, 0, 9)"
      ],
      "metadata": {
        "id": "dG9uau9tR4BX"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding accuracy, precision, recall and f1 score for the model\n",
        "accuracy_percentage_model_3=(accuracy_score(y_test,y_pred))*100\n",
        "precision_percentage_model_3=(precision_score(y_test, y_pred, average=\"weighted\"))*100\n",
        "recall_percentage_model_3=(recall_score(y_test,y_pred, average=\"weighted\"))*100\n",
        "f1_percentage_model_3=(f1_score(y_test,y_pred, average=\"weighted\"))*100\n",
        "\n",
        "print(\"Vanilla Linear Regression Stats:\")\n",
        "print(f\"Accuracy: {accuracy_percentage_model_3:.2f}%\")\n",
        "print(f\"Precision: {precision_percentage_model_3:.2f}%\")\n",
        "print(f\"Recall: {recall_percentage_model_3:.2f}%\")\n",
        "print(f\"F1 Score: {f1_percentage_model_3:.2f}%\")\n",
        "print(f\"Training time: {training_time_model_3:.2f}sec\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52MDyjdSYgIK",
        "outputId": "1356d807-dcac-4717-99dc-01c717ba35fa"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vanilla Linear Regression Stats:\n",
            "Accuracy: 9.35%\n",
            "Precision: 7.01%\n",
            "Recall: 9.35%\n",
            "F1 Score: 6.28%\n",
            "Training time: 0.12sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fourier Features Regreesion"
      ],
      "metadata": {
        "id": "V-zYcQhyac8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Apply PCA to reduce to 1 dimensions\n",
        "pca = PCA(n_components=1)\n",
        "x_train_pca = pca.fit_transform(x_train)\n",
        "x_test_pca = pca.transform(x_test)\n",
        "\n",
        "# Creating Fourier Function\n",
        "start_time = time.time()\n",
        "num_terms = 50\n",
        "\n",
        "# Compute Fourier basis features\n",
        "x_train_fourier = np.hstack([np.sin((i+1) * x_train_pca) for i in range(num_terms)] +\n",
        "                            [np.cos((i+1) * x_train_pca) for i in range(num_terms)])\n",
        "\n",
        "x_test_fourier = np.hstack([np.sin((i+1) * x_test_pca) for i in range(num_terms)] +\n",
        "                           [np.cos((i+1) * x_test_pca) for i in range(num_terms)])\n",
        "\n",
        "# Train Linear Regression model\n",
        "lin_reg_4 = LinearRegression()\n",
        "lin_reg_4.fit(x_train_fourier, y_train)\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculating training time\n",
        "training_time_model_4 = end_time-start_time\n",
        "\n",
        "# Make predictions\n",
        "y_pred = lin_reg_4.predict(x_test_fourier)\n",
        "y_pred = np.round(y_pred).astype(int)\n",
        "y_pred = np.clip(y_pred, 0, 9)"
      ],
      "metadata": {
        "id": "yoEG-ZH9ZGlS"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding accuracy, precision, recall and f1 score for the model\n",
        "accuracy_percentage_model_4=(accuracy_score(y_test,y_pred))*100\n",
        "precision_percentage_model_4=(precision_score(y_test, y_pred, average=\"weighted\"))*100\n",
        "recall_percentage_model_4=(recall_score(y_test,y_pred, average=\"weighted\"))*100\n",
        "f1_percentage_model_4=(f1_score(y_test,y_pred, average=\"weighted\"))*100\n",
        "\n",
        "print(\"Vanilla Linear Regression Stats:\")\n",
        "print(f\"Accuracy: {accuracy_percentage_model_4:.2f}%\")\n",
        "print(f\"Precision: {precision_percentage_model_4:.2f}%\")\n",
        "print(f\"Recall: {recall_percentage_model_4:.2f}%\")\n",
        "print(f\"F1 Score: {f1_percentage_model_4:.2f}%\")\n",
        "print(f\"Training time: {training_time_model_4:.2f}sec\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3KSlgxGeTUX",
        "outputId": "be909052-e6e7-4340-e874-e468d8f273fa"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vanilla Linear Regression Stats:\n",
            "Accuracy: 9.20%\n",
            "Precision: 5.53%\n",
            "Recall: 9.20%\n",
            "F1 Score: 5.07%\n",
            "Training time: 0.36sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion\n",
        "Linear Regression will give bad results for this type of data as the data is non linear and less distinction and we are using PCA for dimensionality reduction making the data too similar which reduces the accuracy."
      ],
      "metadata": {
        "id": "gX_MxJYjfM2B"
      }
    }
  ]
}